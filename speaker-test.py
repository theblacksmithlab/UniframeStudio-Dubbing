#!/usr/bin/env python3
"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è speaker diarization
"""

import json
import sys
from pathlib import Path
import argparse


def test_diarization(audio_path: str, output_path: str = None, hf_token: str = None):
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç speaker diarization –Ω–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–µ
    """
    try:
        from pyannote.audio import Pipeline
        import torch

        print(f"üéµ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∞—É–¥–∏–æ: {audio_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞
        if not Path(audio_path).exists():
            raise FileNotFoundError(f"–ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")

        # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–æ–ø—ã—Ç–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏
        models_to_try = [
            "pyannote/speaker-diarization-3.1",
            "pyannote/speaker-diarization",
            "pyannote/speaker-diarization-3.0"
        ]

        pipeline = None
        successful_model = None

        for model_name in models_to_try:
            try:
                print(f"üì• –ü—Ä–æ–±—É—é –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {model_name}")
                pipeline = Pipeline.from_pretrained(
                    model_name,
                    use_auth_token=hf_token
                )
                successful_model = model_name
                print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                break
            except Exception as e:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {model_name}: {str(e)[:100]}...")
                continue

        if pipeline is None:
            print("\nüîë –í—Å–µ –º–æ–¥–µ–ª–∏ —Ç—Ä–µ–±—É—é—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã!")
            print("1. –°–æ–∑–¥–∞–π—Ç–µ —Ç–æ–∫–µ–Ω: https://huggingface.co/settings/tokens")
            print("2. –ü—Ä–∏–º–∏—Ç–µ —É—Å–ª–æ–≤–∏—è: https://huggingface.co/pyannote/speaker-diarization-3.1")
            print("3. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: python speaker-test.py audio.wav --token YOUR_TOKEN")
            return None

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        pipeline = pipeline.to(device)
        print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å: {successful_model}")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
        print("üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–ø–∏–∫–µ—Ä–æ–≤... (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)")
        diarization = pipeline(audio_path)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —É–¥–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        speakers_timeline = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            speakers_timeline.append({
                "start": float(turn.start),
                "end": float(turn.end),
                "speaker": speaker,
                "duration": float(turn.end - turn.start)
            })

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        speakers_timeline.sort(key=lambda x: x["start"])

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            "model_used": successful_model,
            "total_duration": max([s["end"] for s in speakers_timeline]) if speakers_timeline else 0,
            "speakers_count": len(set([s["speaker"] for s in speakers_timeline])),
            "speakers_found": sorted(list(set([s["speaker"] for s in speakers_timeline]))),
            "timeline": speakers_timeline
        }

        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print("\n" + "=" * 60)
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê –°–ü–ò–ö–ï–†–û–í")
        print("=" * 60)
        print(f"–ú–æ–¥–µ–ª—å: {successful_model}")
        print(f"–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {result['total_duration']:.2f} —Å–µ–∫")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {result['speakers_count']}")
        print(f"–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å–ø–∏–∫–µ—Ä—ã: {', '.join(result['speakers_found'])}")
        print(f"–í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(speakers_timeline)}")
        print("\nüìã –í—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ (–ø–µ—Ä–≤—ã–µ 15 —Å–µ–≥–º–µ–Ω—Ç–æ–≤):")

        for i, segment in enumerate(speakers_timeline[:15]):
            print(f"  {i + 1:2d}. {segment['start']:7.2f}s - {segment['end']:7.2f}s "
                  f"({segment['duration']:5.2f}s) | {segment['speaker']}")

        if len(speakers_timeline) > 15:
            print(f"  ... –∏ –µ—â—ë {len(speakers_timeline) - 15} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º:")
        for speaker in result['speakers_found']:
            speaker_segments = [s for s in speakers_timeline if s['speaker'] == speaker]
            total_time = sum([s['duration'] for s in speaker_segments])
            percentage = (total_time / result['total_duration']) * 100
            print(f"  {speaker}: {total_time:.1f}s ({percentage:.1f}%) –≤ {len(speaker_segments)} —Å–µ–≥–º–µ–Ω—Ç–∞—Ö")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–∞–π–ª
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_path}")

        return result

    except ImportError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install pyannote.audio torch torchaudio")
        return None

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    parser = argparse.ArgumentParser(description="–¢–µ—Å—Ç speaker diarization (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)")
    parser.add_argument("audio_path", help="–ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É")
    parser.add_argument("-o", "--output", help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
    parser.add_argument("--token", help="HuggingFace —Ç–æ–∫–µ–Ω –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")

    args = parser.parse_args()

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º diarization
    result = test_diarization(args.audio_path, args.output, args.token)

    if result:
        print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")
        print("\nüîó –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ –≤ –≤–∞—à python-dubbing-service")
        print("üí° –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞")
    else:
        print("\n‚ùå –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω —Å –æ—à–∏–±–∫–æ–π")


if __name__ == "__main__":
    main()