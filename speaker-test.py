#!/usr/bin/env python3
"""
–†–∞–±–æ—á–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è speaker diarization –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
"""

import json
import torch
import torchaudio
import warnings
from pathlib import Path
import argparse

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –≤—ã–≤–æ–¥–∞
warnings.filterwarnings("ignore")


def test_speaker_diarization(audio_path: str, token: str, output_path: str = None, num_speakers: int = None):
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç speaker diarization –∏—Å–ø–æ–ª—å–∑—É—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π API

    Args:
        audio_path: –ø—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
        token: HuggingFace —Ç–æ–∫–µ–Ω
        output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        num_speakers: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–æ)
    """
    try:
        from pyannote.audio import Pipeline
        from pyannote.audio.pipelines.utils.hook import ProgressHook

        print(f"üéµ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∞—É–¥–∏–æ: {audio_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞
        if not Path(audio_path).exists():
            raise FileNotFoundError(f"–ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        print("üì• –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å speaker-diarization-3.1...")
        pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.1",
            use_auth_token=token
        )

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        pipeline.to(device)
        print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

        # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        print("üîÑ –ó–∞–≥—Ä—É–∂–∞—é –∞—É–¥–∏–æ –≤ –ø–∞–º—è—Ç—å...")
        waveform, sample_rate = torchaudio.load(audio_path)
        audio_data = {"waveform": waveform, "sample_rate": sample_rate}

        # –ì–æ—Ç–æ–≤–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è diarization
        diarization_params = {}
        if num_speakers:
            diarization_params["num_speakers"] = num_speakers
            print(f"üéôÔ∏è –û–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {num_speakers}")

        # –ó–∞–ø—É—Å–∫–∞–µ–º diarization —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        print("üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–ø–∏–∫–µ—Ä–æ–≤...")
        with ProgressHook() as hook:
            diarization = pipeline(audio_data, hook=hook, **diarization_params)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —É–¥–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        speakers_timeline = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            speakers_timeline.append({
                "start": float(turn.start),
                "end": float(turn.end),
                "speaker": speaker,
                "duration": float(turn.end - turn.start)
            })

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        speakers_timeline.sort(key=lambda x: x["start"])

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        speakers_found = sorted(list(set([s["speaker"] for s in speakers_timeline])))
        total_duration = max([s["end"] for s in speakers_timeline]) if speakers_timeline else 0

        result = {
            "audio_file": audio_path,
            "model": "pyannote/speaker-diarization-3.1",
            "total_duration": total_duration,
            "speakers_count": len(speakers_found),
            "speakers_found": speakers_found,
            "total_segments": len(speakers_timeline),
            "timeline": speakers_timeline
        }

        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print("\n" + "=" * 60)
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ SPEAKER DIARIZATION")
        print("=" * 60)
        print(f"–§–∞–π–ª: {audio_path}")
        print(f"–ú–æ–¥–µ–ª—å: pyannote/speaker-diarization-3.1")
        print(f"–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_duration:.2f} —Å–µ–∫")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {len(speakers_found)}")
        print(f"–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å–ø–∏–∫–µ—Ä—ã: {', '.join(speakers_found)}")
        print(f"–í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(speakers_timeline)}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º:")
        for speaker in speakers_found:
            speaker_segments = [s for s in speakers_timeline if s['speaker'] == speaker]
            speaker_time = sum([s['duration'] for s in speaker_segments])
            percentage = (speaker_time / total_duration) * 100 if total_duration > 0 else 0
            print(f"  {speaker}: {speaker_time:.1f}s ({percentage:.1f}%) –≤ {len(speaker_segments)} —Å–µ–≥–º–µ–Ω—Ç–∞—Ö")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ä–∞–∑–º–µ—Ç–∫—É
        print(f"\nüìã –í—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ (–ø–µ—Ä–≤—ã–µ 20 —Å–µ–≥–º–µ–Ω—Ç–æ–≤):")
        for i, segment in enumerate(speakers_timeline[:20]):
            print(f"  {i + 1:2d}. {segment['start']:7.2f}s - {segment['end']:7.2f}s "
                  f"({segment['duration']:5.2f}s) | {segment['speaker']}")

        if len(speakers_timeline) > 20:
            print(f"  ... –∏ –µ—â—ë {len(speakers_timeline) - 20} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            print(f"\nüíæ JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_path}")

        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ RTTM —Ñ–æ—Ä–º–∞—Ç–µ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è diarization)
        rttm_path = Path(audio_path).with_suffix('.rttm')
        with open(rttm_path, "w") as rttm:
            diarization.write_rttm(rttm)
        print(f"üìÑ RTTM —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {rttm_path}")

        return result

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    parser = argparse.ArgumentParser(description="Speaker Diarization —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º API")
    parser.add_argument("audio_path", help="–ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É")
    parser.add_argument("--token", required=True, help="HuggingFace —Ç–æ–∫–µ–Ω")
    parser.add_argument("-o", "--output", help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
    parser.add_argument("--speakers", type=int, help="–û–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤")

    args = parser.parse_args()

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º diarization
    result = test_speaker_diarization(
        audio_path=args.audio_path,
        token=args.token,
        output_path=args.output,
        num_speakers=args.speakers
    )

    if result:
        print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {result['speakers_count']} —Å–ø–∏–∫–µ—Ä–æ–≤ –≤ {result['total_segments']} —Å–µ–≥–º–µ–Ω—Ç–∞—Ö")
        print("\nüîó –¢–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ –≤ –≤–∞—à python-dubbing-service")
        print("üí° –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ—á–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞")
    else:
        print("\n‚ùå –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω —Å –æ—à–∏–±–∫–æ–π")


if __name__ == "__main__":
    main()