import json
import librosa
import numpy as np
from pathlib import Path
import argparse
import warnings

warnings.filterwarnings("ignore")


def analyze_voice_frequency_tuned(audio_path: str, start_time: float, end_time: float, sr: int = 16000):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é —á–∞—Å—Ç–æ—Ç—É –≥–æ–ª–æ—Å–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏
    """
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
        y, sr = librosa.load(audio_path, sr=sr)

        # –í—ã—Ä–µ–∑–∞–µ–º –Ω—É–∂–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç
        start_sample = int(start_time * sr)
        end_sample = int(end_time * sr)
        segment = y[start_sample:end_sample]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —á–∞—Å—Ç–æ—Ç—É (F0)
        f0 = librosa.yin(segment,
                         fmin=50,  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ (Hz)
                         fmax=400,  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ (Hz)
                         sr=sr)

        # –£–±–∏—Ä–∞–µ–º –Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–±–µ–∑–≥–æ–ª–æ—Å—ã–µ —É—á–∞—Å—Ç–∫–∏)
        voiced_f0 = f0[f0 > 0]

        if len(voiced_f0) == 0:
            return {
                "f0_mean": 0,
                "f0_median": 0,
                "f0_std": 0,
                "f0_min": 0,
                "f0_max": 0,
                "voiced_ratio": 0,
                "gender": "unknown",
                "confidence": 0,
                "decision_reason": "no_voice_detected"
            }

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        f0_mean = np.mean(voiced_f0)
        f0_median = np.median(voiced_f0)
        f0_std = np.std(voiced_f0)
        f0_min = np.min(voiced_f0)
        f0_max = np.max(voiced_f0)
        voiced_ratio = len(voiced_f0) / len(f0)

        # –ù–û–í–´–ï –£–õ–£–ß–®–ï–ù–ù–´–ï –ü–û–†–û–ì–ò
        # –°–º–µ—â–∞–µ–º –≤ –ø–æ–ª—å–∑—É –∂–µ–Ω—Å–∫–∏—Ö –≥–æ–ª–æ—Å–æ–≤

        gender = "unknown"
        confidence = 0
        decision_reason = ""

        # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–µ –≥–æ–ª–æ—Å–∞ - —Ç–æ—á–Ω–æ –º—É–∂—Å–∫–∏–µ
        if f0_median < 110:
            gender = "male"
            confidence = min(1.0, (110 - f0_median) / 40)  # —á–µ–º –Ω–∏–∂–µ, —Ç–µ–º —É–≤–µ—Ä–µ–Ω–Ω–µ–µ
            decision_reason = f"very_low_f0_{f0_median:.1f}Hz"

        # –ù–∏–∑–∫–∏–µ –≥–æ–ª–æ—Å–∞ - —Å–∫–æ—Ä–µ–µ –º—É–∂—Å–∫–∏–µ
        elif f0_median < 130:
            gender = "male"
            confidence = min(0.8, (130 - f0_median) / 25)
            decision_reason = f"low_f0_{f0_median:.1f}Hz"

        # –°—Ä–µ–¥–Ω–µ-–Ω–∏–∑–∫–∏–µ –≥–æ–ª–æ—Å–∞ - –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∏–∑–∫–∏–π –∂–µ–Ω—Å–∫–∏–π
        elif f0_median < 145:
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
            if f0_std > 25:  # –≤—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å -> –∂–µ–Ω—Å–∫–∏–π
                gender = "female"
                confidence = 0.4
                decision_reason = f"medium_low_f0_{f0_median:.1f}Hz_high_variability_{f0_std:.1f}"
            else:
                gender = "male"
                confidence = 0.5
                decision_reason = f"medium_low_f0_{f0_median:.1f}Hz_low_variability_{f0_std:.1f}"

        # –°—Ä–µ–¥–Ω–∏–µ –≥–æ–ª–æ—Å–∞ - —Å–µ—Ä–∞—è –∑–æ–Ω–∞, –±–æ–ª—å—à–µ –ø—Ä–æ–≤–µ—Ä–æ–∫
        elif f0_median < 165:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –∏ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
            f0_range = f0_max - f0_min

            # –ï—Å–ª–∏ –µ—Å—Ç—å –≤—ã—Å–æ–∫–∏–µ –ø–∏–∫–∏ - –≤–µ—Ä–æ—è—Ç–Ω–æ –∂–µ–Ω—Å–∫–∏–π
            if f0_max > 200:
                gender = "female"
                confidence = 0.6
                decision_reason = f"medium_f0_{f0_median:.1f}Hz_high_peaks_{f0_max:.1f}Hz"
            # –í—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å - —Å–∫–æ—Ä–µ–µ –∂–µ–Ω—Å–∫–∏–π
            elif f0_std > 30:
                gender = "female"
                confidence = 0.5
                decision_reason = f"medium_f0_{f0_median:.1f}Hz_high_variability_{f0_std:.1f}"
            # –ë–æ–ª—å—à–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω - —Å–∫–æ—Ä–µ–µ –∂–µ–Ω—Å–∫–∏–π
            elif f0_range > 80:
                gender = "female"
                confidence = 0.4
                decision_reason = f"medium_f0_{f0_median:.1f}Hz_wide_range_{f0_range:.1f}Hz"
            else:
                gender = "uncertain"
                confidence = 0.2
                decision_reason = f"medium_f0_{f0_median:.1f}Hz_ambiguous"

        # –°—Ä–µ–¥–Ω–µ-–≤—ã—Å–æ–∫–∏–µ –≥–æ–ª–æ—Å–∞ - —Å–∫–æ—Ä–µ–µ –∂–µ–Ω—Å–∫–∏–µ
        elif f0_median < 185:
            gender = "female"
            confidence = 0.7
            decision_reason = f"medium_high_f0_{f0_median:.1f}Hz"

        # –í—ã—Å–æ–∫–∏–µ –≥–æ–ª–æ—Å–∞ - –∂–µ–Ω—Å–∫–∏–µ
        elif f0_median < 220:
            gender = "female"
            confidence = 0.9
            decision_reason = f"high_f0_{f0_median:.1f}Hz"

        # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–µ –≥–æ–ª–æ—Å–∞ - —Ç–æ—á–Ω–æ –∂–µ–Ω—Å–∫–∏–µ
        else:
            gender = "female"
            confidence = 1.0
            decision_reason = f"very_high_f0_{f0_median:.1f}Hz"

        return {
            "f0_mean": float(f0_mean),
            "f0_median": float(f0_median),
            "f0_std": float(f0_std),
            "f0_min": float(f0_min),
            "f0_max": float(f0_max),
            "f0_range": float(f0_max - f0_min),
            "voiced_ratio": float(voiced_ratio),
            "gender": gender,
            "confidence": float(confidence),
            "decision_reason": decision_reason
        }

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ {start_time}-{end_time}: {e}")
        return {
            "f0_mean": 0,
            "f0_median": 0,
            "f0_std": 0,
            "f0_min": 0,
            "f0_max": 0,
            "f0_range": 0,
            "voiced_ratio": 0,
            "gender": "error",
            "confidence": 0,
            "decision_reason": "processing_error"
        }


def add_tuned_gender_to_segments(audio_path: str, segments: list, output_path: str = None):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª–µ —Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏
    """
    try:
        print(f"üéµ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–æ–ª —Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏ –¥–ª—è {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç
        for i, segment in enumerate(segments):
            if i % 10 == 0:
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(segments)}")

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–∞—Å—Ç–æ—Ç—É –≥–æ–ª–æ—Å–∞
            gender_info = analyze_voice_frequency_tuned(
                audio_path,
                segment["start"],
                segment["end"]
            )

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª–µ
            segment["tuned_gender_analysis"] = gender_info
            segment["predicted_gender"] = gender_info["gender"]
            segment["gender_confidence"] = gender_info["confidence"]
            segment["decision_reason"] = gender_info["decision_reason"]

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print("\n" + "=" * 60)
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –° –ù–ê–°–¢–†–û–ï–ù–ù–´–ú–ò –ü–û–†–û–ì–ê–ú–ò")
        print("=" * 60)

        gender_stats = {}
        confidence_stats = {"high": 0, "medium": 0, "low": 0}

        for segment in segments:
            gender = segment["predicted_gender"]
            confidence = segment["gender_confidence"]

            if gender not in gender_stats:
                gender_stats[gender] = {
                    "count": 0,
                    "total_duration": 0,
                    "avg_confidence": []
                }

            gender_stats[gender]["count"] += 1
            gender_stats[gender]["total_duration"] += segment.get("original_duration",
                                                                  segment["end"] - segment["start"])
            gender_stats[gender]["avg_confidence"].append(confidence)

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            if confidence > 0.7:
                confidence_stats["high"] += 1
            elif confidence > 0.4:
                confidence_stats["medium"] += 1
            else:
                confidence_stats["low"] += 1

        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for gender, stats in gender_stats.items():
            avg_conf = np.mean(stats["avg_confidence"]) if stats["avg_confidence"] else 0
            percentage = (stats["count"] / len(segments)) * 100
            print(f"{gender.upper()}: {stats['count']} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ({percentage:.1f}%) | "
                  f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {stats['total_duration']:.1f}s | "
                  f"–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_conf:.2f}")

        print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:")
        print(f"  –í—ã—Å–æ–∫–∞—è (>0.7): {confidence_stats['high']} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        print(f"  –°—Ä–µ–¥–Ω—è—è (0.4-0.7): {confidence_stats['medium']} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        print(f"  –ù–∏–∑–∫–∞—è (<0.4): {confidence_stats['low']} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Ä–µ—à–µ–Ω–∏–π
        print(f"\nüìã –ü—Ä–∏–º–µ—Ä—ã —Ä–µ—à–µ–Ω–∏–π:")
        examples_shown = 0
        for segment in segments:
            if examples_shown >= 10:
                break
            if segment["predicted_gender"] in ["male", "female"]:
                analysis = segment["tuned_gender_analysis"]
                print(f"  {segment['start']:5.1f}s-{segment['end']:5.1f}s | "
                      f"F0: {analysis['f0_median']:.1f}Hz "
                      f"(¬±{analysis['f0_std']:.1f}, range: {analysis['f0_range']:.1f}) | "
                      f"{segment['predicted_gender']} ({segment['gender_confidence']:.2f}) | "
                      f"{segment['decision_reason']}")
                examples_shown += 1

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(segments, f, indent=2, ensure_ascii=False)
            print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_path}")

        return segments

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    parser = argparse.ArgumentParser(description="–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ —Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏")
    parser.add_argument("audio_path", help="–ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É")
    parser.add_argument("segments_path", help="–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏")
    parser.add_argument("-o", "--output", help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
    if not Path(args.audio_path).exists():
        print(f"‚ùå –ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.audio_path}")
        return

    if not Path(args.segments_path).exists():
        print(f"‚ùå –§–∞–π–ª —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.segments_path}")
        return

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
    try:
        with open(args.segments_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # –ò—â–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
        if "segments" in data:
            segments = data["segments"]
        elif isinstance(data, list):
            segments = data
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ —Ñ–∞–π–ª–µ")
            return

        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ª
        result = add_tuned_gender_to_segments(args.audio_path, segments, args.output)

        if result:
            print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ —Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏ –∑–∞–≤–µ—Ä—à—ë–Ω!")
            print("üéØ –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ª—É—á—à–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∂–µ–Ω—Å–∫–∏—Ö –≥–æ–ª–æ—Å–æ–≤")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {e}")


if __name__ == "__main__":
    main()