#!/usr/bin/env python3
"""
–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ —Å–ø–∏–∫–µ—Ä–∞ –ø–æ —á–∞—Å—Ç–æ—Ç–µ –≥–æ–ª–æ—Å–∞ (F0)
"""

import json
import librosa
import numpy as np
from pathlib import Path
import argparse
import warnings

warnings.filterwarnings("ignore")


def analyze_voice_frequency(audio_path: str, start_time: float, end_time: float, sr: int = 16000):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é —á–∞—Å—Ç–æ—Ç—É –≥–æ–ª–æ—Å–∞ (F0) –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ–ª–∞

    Args:
        audio_path: –ø—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
        start_time: –Ω–∞—á–∞–ª–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        end_time: –∫–æ–Ω–µ—Ü —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        sr: —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏

    Returns:
        dict: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —á–∞—Å—Ç–æ—Ç–µ –∏ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–æ–º –ø–æ–ª–µ
    """
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
        y, sr = librosa.load(audio_path, sr=sr)

        # –í—ã—Ä–µ–∑–∞–µ–º –Ω—É–∂–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç
        start_sample = int(start_time * sr)
        end_sample = int(end_time * sr)
        segment = y[start_sample:end_sample]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —á–∞—Å—Ç–æ—Ç—É (F0)
        f0 = librosa.yin(segment,
                         fmin=50,  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ (Hz)
                         fmax=400,  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ (Hz)
                         sr=sr)

        # –£–±–∏—Ä–∞–µ–º –Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–±–µ–∑–≥–æ–ª–æ—Å—ã–µ —É—á–∞—Å—Ç–∫–∏)
        voiced_f0 = f0[f0 > 0]

        if len(voiced_f0) == 0:
            return {
                "f0_mean": 0,
                "f0_median": 0,
                "f0_std": 0,
                "voiced_ratio": 0,
                "gender": "unknown",
                "confidence": 0
            }

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        f0_mean = np.mean(voiced_f0)
        f0_median = np.median(voiced_f0)
        f0_std = np.std(voiced_f0)
        voiced_ratio = len(voiced_f0) / len(f0)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç—ã
        # –¢–∏–ø–∏—á–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã:
        # –ú—É–∂—á–∏–Ω—ã: 85-180 Hz (—Å—Ä–µ–¥–Ω–µ–µ ~120 Hz)
        # –ñ–µ–Ω—â–∏–Ω—ã: 165-265 Hz (—Å—Ä–µ–¥–Ω–µ–µ ~210 Hz)

        gender = "unknown"
        confidence = 0

        if f0_median < 140:
            gender = "male"
            # –ß–µ–º –Ω–∏–∂–µ —á–∞—Å—Ç–æ—Ç–∞, —Ç–µ–º –≤—ã—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidence = min(1.0, (140 - f0_median) / 55)
        elif f0_median > 160:
            gender = "female"
            # –ß–µ–º –≤—ã—à–µ —á–∞—Å—Ç–æ—Ç–∞, —Ç–µ–º –≤—ã—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidence = min(1.0, (f0_median - 160) / 105)
        else:
            # –ü–µ—Ä–µ—Ö–æ–¥–Ω–∞—è –∑–æ–Ω–∞ 140-160 Hz
            gender = "uncertain"
            confidence = 0.3

        return {
            "f0_mean": float(f0_mean),
            "f0_median": float(f0_median),
            "f0_std": float(f0_std),
            "voiced_ratio": float(voiced_ratio),
            "gender": gender,
            "confidence": float(confidence)
        }

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ {start_time}-{end_time}: {e}")
        return {
            "f0_mean": 0,
            "f0_median": 0,
            "f0_std": 0,
            "voiced_ratio": 0,
            "gender": "error",
            "confidence": 0
        }


def add_gender_to_segments(audio_path: str, segments: list, output_path: str = None):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª–µ –∫ —Å–µ–≥–º–µ–Ω—Ç–∞–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏

    Args:
        audio_path: –ø—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
        segments: —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
        output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    """
    try:
        print(f"üéµ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–æ–ª —Å–ø–∏–∫–µ—Ä–æ–≤ –≤ {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–∞—Ö...")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç
        for i, segment in enumerate(segments):
            if i % 10 == 0:
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(segments)}")

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–∞—Å—Ç–æ—Ç—É –≥–æ–ª–æ—Å–∞
            gender_info = analyze_voice_frequency(
                audio_path,
                segment["start"],
                segment["end"]
            )

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª–µ
            segment["gender_analysis"] = gender_info
            segment["predicted_gender"] = gender_info["gender"]
            segment["gender_confidence"] = gender_info["confidence"]

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print("\n" + "=" * 50)
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê –ü–û–õ–ê")
        print("=" * 50)

        gender_stats = {}
        for segment in segments:
            gender = segment["predicted_gender"]
            if gender not in gender_stats:
                gender_stats[gender] = {"count": 0, "total_duration": 0}
            gender_stats[gender]["count"] += 1
            gender_stats[gender]["total_duration"] += segment.get("original_duration", 0)

        for gender, stats in gender_stats.items():
            print(f"{gender.upper()}: {stats['count']} —Å–µ–≥–º–µ–Ω—Ç–æ–≤, "
                  f"{stats['total_duration']:.1f}s –æ–±—â–µ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
        print(f"\nüìã –ü—Ä–∏–º–µ—Ä—ã –∞–Ω–∞–ª–∏–∑–∞ (–ø–µ—Ä–≤—ã–µ 10 —Å–µ–≥–º–µ–Ω—Ç–æ–≤):")
        for i, segment in enumerate(segments[:10]):
            gender_info = segment["gender_analysis"]
            print(f"  {i + 1:2d}. {segment['start']:6.2f}s - {segment['end']:6.2f}s | "
                  f"F0: {gender_info['f0_median']:.1f}Hz | "
                  f"–ü–æ–ª: {segment['predicted_gender']} ({segment['gender_confidence']:.2f})")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(segments, f, indent=2, ensure_ascii=False)
            print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_path}")

        return segments

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return None


def test_gender_detection(audio_path: str, segments_path: str, output_path: str = None):
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        print(f"üîÑ –ó–∞–≥—Ä—É–∂–∞—é —Å–µ–≥–º–µ–Ω—Ç—ã –∏–∑: {segments_path}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
        with open(segments_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # –ò—â–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
        segments = None
        if "segments" in data:
            segments = data["segments"]
        elif isinstance(data, list):
            segments = data
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ —Ñ–∞–π–ª–µ")
            return None

        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ª
        result = add_gender_to_segments(audio_path, segments, output_path)

        if result:
            print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –ø–æ–ª–∞ –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")
            print("üí° –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å predicted_gender –¥–ª—è –≤—ã–±–æ—Ä–∞ –≥–æ–ª–æ—Å–∞ TTS")

        return result

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    parser = argparse.ArgumentParser(description="–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ –ø–æ —á–∞—Å—Ç–æ—Ç–µ –≥–æ–ª–æ—Å–∞")
    parser.add_argument("audio_path", help="–ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É")
    parser.add_argument("segments_path", help="–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏")
    parser.add_argument("-o", "--output", help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
    if not Path(args.audio_path).exists():
        print(f"‚ùå –ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.audio_path}")
        return

    if not Path(args.segments_path).exists():
        print(f"‚ùå –§–∞–π–ª —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.segments_path}")
        return

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞
    result = test_gender_detection(args.audio_path, args.segments_path, args.output)


if __name__ == "__main__":
    main()